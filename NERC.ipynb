{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'words': 'EU', 'pos': 'NNP'}, {'words': 'rejects', 'pos': 'VBZ'}, {'words': 'German', 'pos': 'JJ'}, {'words': 'call', 'pos': 'NN'}, {'words': 'to', 'pos': 'TO'}, {'words': 'boycott', 'pos': 'VB'}, {'words': 'British', 'pos': 'JJ'}, {'words': 'lamb', 'pos': 'NN'}, {'words': '.', 'pos': '.'}, {'words': 'Peter', 'pos': 'NNP'}]\n",
      "203621\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "train = ConllCorpusReader('CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "        'words': token,\n",
    "        'pos': pos,\n",
    "        'labels': ne_label\n",
    "       # add features\n",
    "    }\n",
    "    training_features.append({'words': a_dict['words'], 'pos': a_dict['pos']})\n",
    "    training_gold_labels.append(a_dict['labels'])\n",
    "print(training_features[:10])\n",
    "training_gold_labels[:10]\n",
    "cutoff = len(training_features)\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "test = pd.read_csv(\"NER-final-test.tsv\",delimiter = '\\t')\n",
    "convert = pos_tag(test.token.tolist())\n",
    "new_pos = []\n",
    "for word, pos in convert:\n",
    "    new_pos.append(pos)\n",
    "test['PoS'] = new_pos\n",
    "test.to_csv('NER-final-test-PoS.csv', index=False)\n",
    "len(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'words': 'EU', 'pos': 'NNP'}, {'words': 'rejects', 'pos': 'VBZ'}, {'words': 'German', 'pos': 'JJ'}, {'words': 'call', 'pos': 'NN'}, {'words': 'to', 'pos': 'TO'}, {'words': 'boycott', 'pos': 'VB'}, {'words': 'British', 'pos': 'JJ'}, {'words': 'lamb', 'pos': 'NN'}, {'words': '.', 'pos': '.'}, {'words': 'Peter', 'pos': 'NNP'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-PER']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gold_labels = test['BIO NER tag'].tolist()\n",
    "test_features = []\n",
    "for word, pos in convert:\n",
    "    test_features.append({'words': word, 'pos': pos})\n",
    "\n",
    "print(training_features[:10])\n",
    "training_gold_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Instances - 203621\n",
      "\n",
      "frequency of labels:\n",
      "B-ORG - 3.1\n",
      "O - 83.28\n",
      "B-MISC - 1.69\n",
      "B-PER - 3.24\n",
      "I-PER - 2.22\n",
      "B-LOC - 3.51\n",
      "I-ORG - 1.82\n",
      "I-MISC - 0.57\n",
      "I-LOC - 0.57\n",
      "\n",
      "\n",
      "Test Set:\n",
      "\n",
      "Instances - 214\n",
      "\n",
      "frequency of labels:\n",
      "O - 85.51\n",
      "B-ORG - 1.87\n",
      "I-ORG - 1.4\n",
      "B-LOC - 1.87\n",
      "B-MISC - 1.4\n",
      "B-PER - 2.8\n",
      "I-PER - 3.74\n",
      "I-MISC - 0.47\n",
      "I-LOC - 0.93\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "print(\"Training Set:\\n\")\n",
    "print(\"Instances - %s\\n\" %(len(training_gold_labels)))\n",
    "print(\"frequency of labels:\")\n",
    "for label, count in Counter(training_gold_labels).items():\n",
    "    print('%s - %s'%(label,round((count/len(training_gold_labels))*100,2)))\n",
    "print(\"\\n\\nTest Set:\\n\")\n",
    "print(\"Instances - %s\\n\" %(len(test_gold_labels)))\n",
    "print(\"frequency of labels:\")\n",
    "for label, count in Counter(test_gold_labels).items():\n",
    "    print('%s - %s'%(label,round((count/len(test_gold_labels))*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "the_array = training_features\n",
    "the_array.extend(test_features)\n",
    "the_array = vec.fit_transform(the_array)\n",
    "training = the_array[:cutoff]\n",
    "testing = the_array[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(training, training_gold_labels)\n",
    "predict = lin_clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.50      0.50      0.50         4\n",
      "      B-MISC       0.67      0.67      0.67         3\n",
      "       B-ORG       0.00      0.00      0.00         4\n",
      "       B-PER       0.75      0.50      0.60         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.50      0.67      0.57         3\n",
      "       I-PER       0.64      0.88      0.74         8\n",
      "           O       0.99      1.00      1.00       183\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.52      0.58      0.54       214\n",
      "weighted avg       0.93      0.94      0.93       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "reportOne = classification_report(test_gold_labels, predict)\n",
    "print(reportOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 'Warner', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: I-PER\n",
      "{'words': 'New', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: B-LOC\n",
      "{'words': 'York', 'pos': 'NNP'}\n",
      "label: I-ORG\n",
      "predict: I-LOC\n",
      "{'words': 'Soho', 'pos': 'NNP'}\n",
      "label: B-LOC\n",
      "predict: I-PER\n",
      "{'words': 'Cuba', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: B-LOC\n",
      "{'words': 'African', 'pos': 'JJ'}\n",
      "label: B-MISC\n",
      "predict: I-MISC\n",
      "{'words': 'American', 'pos': 'JJ'}\n",
      "label: I-MISC\n",
      "predict: B-MISC\n",
      "{'words': 'Navy', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: I-ORG\n",
      "{'words': 'Amsterdam', 'pos': 'NNP'}\n",
      "label: B-LOC\n",
      "predict: I-ORG\n",
      "{'words': 'Blauwbrug', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: I-PER\n",
      "{'words': 'Dame', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: I-PER\n",
      "{'words': 'Maggie', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: B-PER\n",
      "{'words': 'Mr.', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: O\n",
      "Number of Correct: 201\n",
      "Number of Incorrect: 13\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "number_wrong = 0\n",
    "number_right = 0\n",
    "for i in test_gold_labels:\n",
    "    if i == predict[j]:\n",
    "        number_right += 1\n",
    "    else:\n",
    "        print(test_features[j])\n",
    "        print('label: %s' %(i))\n",
    "        print('predict: %s' %(predict[j]))\n",
    "        number_wrong += 1\n",
    "    j+=1\n",
    "print(f'Number of Correct: {number_right}')\n",
    "print(f'Number of Incorrect: {number_wrong}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = []\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "        'words': token,\n",
    "        'pos' : pos,\n",
    "        'ne_label' : ne_label\n",
    "    }\n",
    "    training_words.append(a_dict['words'])\n",
    "\n",
    "test_words = []\n",
    "\n",
    "for word, pos in convert:\n",
    "    test_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/Thomas/Documents/GitHub/ba-text-mining/lab_sessions/lab4/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.60      0.75      0.67         4\n",
      "      B-MISC       0.75      1.00      0.86         3\n",
      "       B-ORG       0.33      0.25      0.29         4\n",
      "       B-PER       0.60      0.50      0.55         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.00      0.00      0.00         3\n",
      "       I-PER       0.67      0.50      0.57         8\n",
      "           O       0.97      1.00      0.99       183\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.51      0.56      0.52       214\n",
      "weighted avg       0.91      0.93      0.92       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "both_input=[]\n",
    "for token in (training_words + test_words): \n",
    "    if token in word_embedding_model:\n",
    "        vector=word_embedding_model[token]\n",
    "    else: \n",
    "        vector=[0]*300\n",
    "    both_input.append(vector)\n",
    "\n",
    "cutoff = len(training_words)\n",
    "training_em = both_input[:cutoff]\n",
    "testing_em = both_input[cutoff:]\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(training_em, training_gold_labels)\n",
    "predict_em = lin_clf.predict(testing_em)\n",
    "reportTwo = classification_report(test_gold_labels, predict_em)\n",
    "print(reportTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 'Warner', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: I-PER\n",
      "{'words': 'Brothers', 'pos': 'NNPS'}\n",
      "label: I-ORG\n",
      "predict: B-ORG\n",
      "{'words': 'New', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: B-LOC\n",
      "{'words': 'York', 'pos': 'NNP'}\n",
      "label: I-ORG\n",
      "predict: I-LOC\n",
      "{'words': 'University', 'pos': 'NNP'}\n",
      "label: I-ORG\n",
      "predict: O\n",
      "{'words': 'Austen', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: B-PER\n",
      "{'words': 'Cuba', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: B-LOC\n",
      "{'words': 'Jr.', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: O\n",
      "{'words': 'American', 'pos': 'JJ'}\n",
      "label: I-MISC\n",
      "predict: B-MISC\n",
      "{'words': 'Blauwbrug', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: O\n",
      "{'words': 'Dame', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: I-PER\n",
      "{'words': 'Maggie', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: B-PER\n",
      "{'words': 'Mr.', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: O\n",
      "{'words': 'Kruno', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: O\n",
      "{'words': 'Los', 'pos': 'NNP'}\n",
      "label: B-LOC\n",
      "predict: B-ORG\n",
      "Number of Correct: 199\n",
      "Number of Incorrect: 15\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "number_wrong = 0\n",
    "number_right = 0\n",
    "for i in test_gold_labels:\n",
    "    if i == predict_em[j]:\n",
    "        #print('correct')\n",
    "        number_right += 1\n",
    "    else:\n",
    "        #print('false')\n",
    "        print(test_features[j])\n",
    "        print('label: %s' %(i))\n",
    "        print('predict: %s' %(predict_em[j]))\n",
    "        number_wrong += 1\n",
    "    j+=1\n",
    "print(f'Number of Correct: {number_right}')\n",
    "print(f'Number of Incorrect: {number_wrong}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'took', 'eight', 'years', 'for', 'Warner', 'Brothers', 'to', 'recover', 'from', 'the', 'disaster', 'that', 'was', 'this', 'movie', '.']\n",
      "['All', 'the', 'New', 'York', 'University', 'students', 'love', 'this', 'diner', 'in', 'Soho', 'so', 'it', 'makes', 'for', 'a', 'fun', 'young', 'atmosphere', '.']\n",
      "['This', 'Italian', 'place', 'is', 'really', 'trendy', 'but', 'they', 'have', 'forgotten', 'about', 'the', 'most', 'important', 'part', 'of', 'a', 'restaurant', ',', 'the', 'food', '.']\n",
      "['In', 'conclusion', ',', 'my', 'review', 'of', 'this', 'book', 'would', 'be', ':', 'I', 'like', 'Jane', 'Austen', 'and', 'understand', 'why', 'she', 'is', 'famous', '.']\n",
      "['The', 'story', 'of', 'this', 'movie', 'is', 'focused', 'on', 'Carl', 'Brashear', 'played', 'by', 'Cuba', 'Gooding', 'Jr.', 'who', 'wants', 'to', 'be', 'the', 'first', 'African', 'American', 'deep', 'sea', 'diver', 'in', 'the', 'Navy', '.']\n",
      "['Chris', \"O'Donnell\", 'stated', 'that', 'while', 'filming', 'for', 'this', 'movie', ',', 'he', 'felt', 'like', 'he', 'was', 'in', 'a', 'toy', 'commercial', '.']\n",
      "['My', 'husband', 'and', 'I', 'moved', 'to', 'Amsterdam', '6', 'years', 'ago', 'and', 'for', 'as', 'long', 'as', 'we', 'have', 'lived', 'here', ',', 'Blauwbrug', 'has', 'been', 'our', 'favorite', 'place', 'to', 'eat', '!']\n",
      "['Dame', 'Maggie', 'Smith', 'performed', 'her', 'role', 'excellently', ',', 'as', 'she', 'does', 'in', 'all', 'her', 'movies', '.']\n",
      "['The', 'new', 'movie', 'by', 'Mr.', 'Kruno', 'was', 'shot', 'in', 'New', 'York', ',', 'but', 'the', 'story', 'takes', 'place', 'in', 'Los', 'Angeles', '.']\n",
      "['I', 'always', 'have', 'loved', 'English', 'novels', ',', 'but', 'I', 'just', 'could', \"n't\", 'get', 'into', 'this', 'one', '.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test = pd.read_csv(\"NER-final-test.tsv\",delimiter = '\\t')\n",
    "j = 0\n",
    "sent = 0\n",
    "sentence = []\n",
    "sentences = []\n",
    "for i in test.token.tolist():\n",
    "    if (j+1) == len(test.token.tolist()):\n",
    "        sentence.append(test.token[j])\n",
    "        sentences.append(sentence)\n",
    "        print(sentence)\n",
    "    elif test['sentence id'][j] == sent:\n",
    "        sentence.append(test.token[j])\n",
    "    else: \n",
    "        print(sentence)\n",
    "        sent += 1\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "        sentence.append(test.token[j])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.ner import NERModel\n",
    "#sentences = [\"Example sentence 1\", \"Example sentence 2\"]\n",
    "englishmodel = NERModel(\n",
    "        model_type=\"bert\",\n",
    "        model_name=\"dslim/bert-base-NER\",\n",
    "        use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I always have loved English novels , but I just could n't get into this one .\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sentences = []\n",
    "punctuations = ['.',',',':','-','!']\n",
    "string = \"\"\n",
    "start = True\n",
    "for i in sentences:\n",
    "    for j in i:\n",
    "        if start == True:\n",
    "                string = \"%s%s\" %(string, j)\n",
    "                start = False\n",
    "        else: \n",
    "            string = \"%s %s\" %(string, j)\n",
    "    str_sentences.append(string)\n",
    "    string = \"\"\n",
    "    start = True\n",
    "str_sentences[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.26s/it]\n",
      "Running Prediction: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = englishmodel.predict(str_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      1.00      0.89         4\n",
      "      B-MISC       1.00      1.00      1.00         3\n",
      "       B-ORG       1.00      0.75      0.86         4\n",
      "       B-PER       0.67      0.67      0.67         6\n",
      "       I-LOC       1.00      1.00      1.00         2\n",
      "      I-MISC       1.00      1.00      1.00         1\n",
      "       I-ORG       1.00      1.00      1.00         3\n",
      "       I-PER       1.00      0.75      0.86         8\n",
      "           O       0.99      1.00      0.99       183\n",
      "\n",
      "    accuracy                           0.98       214\n",
      "   macro avg       0.94      0.91      0.92       214\n",
      "weighted avg       0.98      0.98      0.98       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for i in predictions:\n",
    "    for j in i:\n",
    "        for k, v in j.items():\n",
    "            pred.append(v)\n",
    "#predictions\n",
    "\n",
    "len(pred)\n",
    "reportThree = classification_report(test_gold_labels, pred)\n",
    "print(reportThree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': 'Blauwbrug', 'pos': 'NNP'}\n",
      "label: B-ORG\n",
      "predict: B-LOC\n",
      "{'words': 'Dame', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: O\n",
      "{'words': 'Maggie', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: B-PER\n",
      "{'words': 'Mr.', 'pos': 'NNP'}\n",
      "label: B-PER\n",
      "predict: O\n",
      "{'words': 'Kruno', 'pos': 'NNP'}\n",
      "label: I-PER\n",
      "predict: B-PER\n",
      "209\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "number_wrong = 0\n",
    "number_right = 0\n",
    "for i in test_gold_labels:\n",
    "    if i == pred[j]:\n",
    "        #print('correct')\n",
    "        number_right += 1\n",
    "    else:\n",
    "        #print('false')\n",
    "        print(test_features[j])\n",
    "        print('label: %s' %(i))\n",
    "        print('predict: %s' %(pred[j]))\n",
    "        number_wrong += 1\n",
    "    j+=1\n",
    "print(number_right)\n",
    "print(number_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "number_rightOne = 201\n",
    "number_wrongOne = 13\n",
    "\n",
    "number_rightTwo = 199\n",
    "number_wrongTwo = 15\n",
    "\n",
    "number_rightThree = 209\n",
    "number_wrongThree = 5\n",
    "\n",
    "data = [number_wrongOne,number_wrongTwo,number_wrongThree]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "thing = ['SVM Incorrect', 'EM SVM Incorrect', 'BERT Incorrect']\n",
    "ax.bar(thing,data)\n",
    "plt.savefig('plot.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.50      0.50      0.50         4\n",
      "      B-MISC       0.67      0.67      0.67         3\n",
      "       B-ORG       0.00      0.00      0.00         4\n",
      "       B-PER       0.75      0.50      0.60         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.50      0.67      0.57         3\n",
      "       I-PER       0.64      0.88      0.74         8\n",
      "           O       0.99      1.00      1.00       183\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.52      0.58      0.54       214\n",
      "weighted avg       0.93      0.94      0.93       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SVM')\n",
    "print(reportOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.60      0.75      0.67         4\n",
      "      B-MISC       0.75      1.00      0.86         3\n",
      "       B-ORG       0.33      0.25      0.29         4\n",
      "       B-PER       0.60      0.50      0.55         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.00      0.00      0.00         3\n",
      "       I-PER       0.67      0.50      0.57         8\n",
      "           O       0.97      1.00      0.99       183\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.51      0.56      0.52       214\n",
      "weighted avg       0.91      0.93      0.92       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('EM SVM')\n",
    "print(reportTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      1.00      0.89         4\n",
      "      B-MISC       1.00      1.00      1.00         3\n",
      "       B-ORG       1.00      0.75      0.86         4\n",
      "       B-PER       0.67      0.67      0.67         6\n",
      "       I-LOC       1.00      1.00      1.00         2\n",
      "      I-MISC       1.00      1.00      1.00         1\n",
      "       I-ORG       1.00      1.00      1.00         3\n",
      "       I-PER       1.00      0.75      0.86         8\n",
      "           O       0.99      1.00      0.99       183\n",
      "\n",
      "    accuracy                           0.98       214\n",
      "   macro avg       0.94      0.91      0.92       214\n",
      "weighted avg       0.98      0.98      0.98       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BERT')\n",
    "print(reportThree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
